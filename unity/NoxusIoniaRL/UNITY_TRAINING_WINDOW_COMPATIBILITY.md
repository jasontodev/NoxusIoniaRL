# Unity Training Window - Full Compatibility Guide

## Short Answer: YES, Everything Still Works!

Using Unity's Training Window is just a **UI wrapper** around the same ML-Agents training. All your other components work exactly the same.

## How Each Component Works

### ✅ PyTorch

**Status**: Fully Compatible

- ML-Agents uses **PyTorch** as the backend (not TensorFlow)
- Unity Training Window still uses PyTorch under the hood
- The training algorithm (PPO) runs the same way
- Model files (.onnx) are generated the same way

**Note**: ML-Agents uses PyTorch by default. If you need TensorFlow specifically, you'd need to use a different RL framework, but PyTorch is the standard for ML-Agents.

### ✅ TensorBoard

**Status**: Fully Compatible

- ML-Agents **always generates TensorBoard logs** regardless of how training starts
- Logs are saved to the same location (typically `results/<run-id>/`)
- You can still run: `tensorboard --logdir results`
- All metrics (rewards, learning curves, etc.) are logged the same way

**Location**: Check Unity Training Window settings for output directory, or look in `results/` folder

### ✅ AWS (EC2, S3)

**Status**: Fully Compatible

**S3 Sync**:
- Training still generates checkpoints, logs, and model files
- Your `infra/aws/s3_sync.sh` script works the same
- Files are in the same locations (checkpoints/, logs/, results/)
- Just sync them to S3 as before

**EC2 Training**:
- For EC2, you'd still use command line (`mlagents-learn`)
- Or use Unity Training Window on EC2 via remote desktop/VNC
- Or build Unity executable and train headless on EC2

**Example S3 Sync After Unity Training**:
```powershell
# Training generates files in results/test_run/
# Sync to S3 as usual
.\infra\aws\s3_sync.sh
```

### ✅ Social Network Analysis (SNA)

**Status**: Fully Compatible - Completely Independent

- SNA service reads **event logs** (JSONL files from EventLogger)
- Event logs are generated by Unity during gameplay
- **Training method doesn't matter** - events are logged the same way
- Your `services/analytics/` service works exactly the same

**Workflow**:
1. Unity Training Window runs training → agents play games
2. EventLogger writes events to `data/logs/events_*.jsonl`
3. Analytics service reads these logs (same as before)
4. NetworkX analysis runs the same way

### ✅ LLM/NLP Service

**Status**: Fully Compatible - Completely Independent

- LLM service analyzes **match logs** (post-game analysis)
- Logs are generated by EventLogger during gameplay
- **Training method doesn't matter** - logs are the same
- Your `services/llm/` service works exactly the same

**Workflow**:
1. Training runs (Unity Window or command line) → games are played
2. EventLogger writes episode_end events with match data
3. LLM service reads these logs and generates analysis
4. Strategy generation works the same way

### ✅ Statistical Modeling & Optimization

**Status**: Fully Compatible

- **Optuna sweeps**: You can still run `python rl/scripts/optuna_sweep.py`
  - It calls `mlagents-learn` internally, but you could modify it to use Unity's API
  - Or run sweeps via command line (even if individual training uses Unity Window)
- **Statistical analysis**: Reads the same TensorBoard logs and event logs
- **Notebooks**: Work with the same data files

## What Unity Training Window Changes

**Only Changes**:
- How you **start** training (UI vs command line)
- Where you **configure** hyperparameters (UI vs YAML file)

**Doesn't Change**:
- Training algorithm (still PPO/PyTorch)
- Log file locations
- Model file formats
- Event logging
- Checkpoint generation
- Any of your Python services

## Recommended Workflow

### Option A: Unity Training Window (Easiest for Local)

1. **Start Training**: Unity → Window → ML-Agents → Training
2. **Monitor**: TensorBoard (same logs as before)
3. **Analyze**: Your analytics/LLM services read the same event logs
4. **Deploy**: Sync results to S3 using your scripts

### Option B: Command Line (For EC2/Automation)

1. **Start Training**: `mlagents-learn config.yaml` (on EC2)
2. **Monitor**: TensorBoard
3. **Analyze**: Same services
4. **Deploy**: S3 sync

### Option C: Hybrid

- Use Unity Window for **local development/testing**
- Use command line for **EC2 production runs**
- Both generate the same outputs!

## File Locations (Same for Both Methods)

After training, you'll find:

```
results/
  test_run/
    NoxusAgent.onnx          # Trained model
    IoniaAgent.onnx
    NoxusAgent_behavior_spec.yaml
    IoniaAgent_behavior_spec.yaml
    summaries/               # TensorBoard logs
      events.out.tfevents...

data/
  logs/
    events_20240101_120000.jsonl  # Event logs for SNA/LLM
  checkpoints/                     # Model checkpoints
```

All your services read from these same locations!

## Integration Points

### TensorBoard
```powershell
# Works the same regardless of training method
tensorboard --logdir results/test_run/summaries
```

### Analytics Service
```python
# Reads event logs - same files regardless of training method
events = load_events("data/logs/events_*.jsonl")
sna.analyze(events)  # Works the same
```

### LLM Service
```python
# Reads match logs - same format regardless of training method
match_log = load_match("data/logs/events_*.jsonl")
llm.analyze(match_log)  # Works the same
```

### S3 Sync
```powershell
# Syncs the same files regardless of training method
.\infra\aws\s3_sync.sh  # Works the same
```

## Conclusion

**Unity Training Window is just a UI convenience** - it doesn't change:
- The training algorithm (PyTorch/PPO)
- The output files (logs, checkpoints, models)
- Your Python services (SNA, LLM, analytics)
- AWS integration (S3, EC2)
- TensorBoard visualization

**Everything works exactly the same!** The only difference is how you click "Start Training" - via UI instead of command line.

